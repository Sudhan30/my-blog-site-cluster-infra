apiVersion: v1
kind: ConfigMap
metadata:
  name: job-fit-backend-code
  namespace: web
data:
  main.py: |
    from fastapi import FastAPI, HTTPException
    from pydantic import BaseModel
    import requests
    import hashlib
    import json
    import re
    from collections import Counter
    from fastapi.middleware.cors import CORSMiddleware
    import os
    from pathlib import Path

    app = FastAPI()

    # Enable CORS for the frontend
    app.add_middleware(
        CORSMiddleware,
        allow_origins=["*"],
        allow_credentials=True,
        allow_methods=["*"],
        allow_headers=["*"],
    )

    CACHE = {}
    OLLAMA_HOST = os.getenv("OLLAMA_HOST", "http://ollama-service:11434")
    PRIVATE_DATA_PATH = Path(os.getenv("PRIVATE_DATA_PATH", "/app/private"))

    # ============= KEYWORD EXTRACTION & MATCHING =============
    TECH_KEYWORDS = {
        # Languages
        "python", "java", "javascript", "typescript", "go", "rust", "scala", "sql", "bash", "shell",
        "c++", "c#", "ruby", "php", "swift", "kotlin", "r",
        # Big Data
        "spark", "hadoop", "kafka", "airflow", "flink", "hive", "presto", "dbt", "databricks",
        # Cloud
        "aws", "gcp", "azure", "s3", "ec2", "lambda", "bigquery", "redshift", "snowflake",
        # Databases
        "postgresql", "postgres", "mysql", "mongodb", "redis", "elasticsearch", "cassandra", "dynamodb",
        # Tools
        "docker", "kubernetes", "k8s", "terraform", "jenkins", "ci/cd", "git", "github", "gitlab",
        # ML/AI
        "machine learning", "ml", "deep learning", "tensorflow", "pytorch", "scikit-learn", "pandas", "numpy",
        # Data
        "etl", "elt", "data pipeline", "data warehouse", "data lake", "analytics", "bi",
        # Roles
        "data engineer", "software engineer", "backend", "senior", "lead", "principal", "staff",
    }

    def extract_keywords(text):
        """Extract tech keywords from text"""
        text_lower = text.lower()
        found = set()
        for kw in TECH_KEYWORDS:
            if kw in text_lower:
                found.add(kw)
        return found

    def calculate_match_score(resume_kw, job_kw, prefs):
        """Calculate match score based on keyword overlap"""
        if not job_kw:
            return 50, [], []

        matched = resume_kw & job_kw
        missing = job_kw - resume_kw
        match_ratio = len(matched) / len(job_kw) if job_kw else 0

        # Base score from keyword match
        score = int(match_ratio * 70) + 30  # 30-100 range

        # Boost for specific preferences
        prefs_interests = set(i.lower() for i in prefs.get("interests", []))
        prefs_disinterests = set(d.lower() for d in prefs.get("disinterests", []))

        # Check for disinterests (penalty)
        for dis in prefs_disinterests:
            if any(dis in kw for kw in job_kw):
                score = max(20, score - 20)

        return min(100, score), list(matched), list(missing)[:5]

    # Load resume and preferences from server files (not from request)
    def load_resume():
        """Load resume from PDF, DOCX, or TXT file on server"""
        resume_path = PRIVATE_DATA_PATH / "resume"

        # Try PDF first
        pdf_path = resume_path.with_suffix(".pdf")
        if pdf_path.exists():
            try:
                import PyPDF2
                with open(pdf_path, "rb") as f:
                    reader = PyPDF2.PdfReader(f)
                    text = ""
                    for page in reader.pages:
                        text += page.extract_text() + "\n"
                print(f"[RESUME] Loaded from PDF: {pdf_path}")
                return text.strip()
            except Exception as e:
                print(f"[RESUME] Error reading PDF: {e}")

        # Try DOCX
        docx_path = resume_path.with_suffix(".docx")
        if docx_path.exists():
            try:
                from docx import Document
                doc = Document(docx_path)
                text = "\n".join([para.text for para in doc.paragraphs])
                print(f"[RESUME] Loaded from DOCX: {docx_path}")
                return text.strip()
            except Exception as e:
                print(f"[RESUME] Error reading DOCX: {e}")

        # Try plain text
        txt_path = resume_path.with_suffix(".txt")
        if txt_path.exists():
            text = txt_path.read_text()
            print(f"[RESUME] Loaded from TXT: {txt_path}")
            return text.strip()

        print(f"[RESUME] No resume file found in {PRIVATE_DATA_PATH}")
        return None

    def load_preferences():
        """Load preferences from JSON file on server"""
        prefs_path = PRIVATE_DATA_PATH / "preferences.json"
        if prefs_path.exists():
            try:
                prefs = json.loads(prefs_path.read_text())
                print(f"[PREFS] Loaded from: {prefs_path}")
                return prefs
            except Exception as e:
                print(f"[PREFS] Error reading preferences: {e}")
        print(f"[PREFS] No preferences file found at {prefs_path}")
        return {}

    # Cache the loaded data
    _resume_cache = None
    _prefs_cache = None
    _resume_keywords = None  # Precomputed keywords

    def get_resume():
        global _resume_cache
        if _resume_cache is None:
            _resume_cache = load_resume()
        return _resume_cache

    def get_preferences():
        global _prefs_cache
        if _prefs_cache is None:
            _prefs_cache = load_preferences()
        return _prefs_cache

    def get_resume_keywords():
        global _resume_keywords
        if _resume_keywords is None:
            resume = get_resume()
            if resume:
                _resume_keywords = extract_keywords(resume)
                print(f"[KEYWORDS] Precomputed {len(_resume_keywords)} resume keywords: {_resume_keywords}")
        return _resume_keywords or set()

    class FitRequest(BaseModel):
        job: str  # Only job description is required from frontend

    def cache_key(job: str):
        return hashlib.sha256(job.encode()).hexdigest()

    # Short prompt for verdict only (LLM just explains precomputed results)
    VERDICT_PROMPT = """Given these job fit metrics, write a 2-sentence verdict.
Score: {score}/100 ({level})
Matched skills: {matched}
Missing skills: {gaps}
Return JSON: {{"summary":"<2 sentences>","verdict":"<1 sentence recommendation>"}}"""

    @app.get("/reload")
    def reload_data():
        """Reload resume and preferences from files"""
        global _resume_cache, _prefs_cache, _resume_keywords
        _resume_cache = None
        _prefs_cache = None
        _resume_keywords = None
        resume = get_resume()
        prefs = get_preferences()
        keywords = get_resume_keywords()
        return {
            "status": "reloaded",
            "resume_loaded": resume is not None,
            "resume_length": len(resume) if resume else 0,
            "resume_keywords": len(keywords),
            "preferences_loaded": bool(prefs)
        }

    @app.post("/job-fit")
    def job_fit(req: FitRequest):
        print("=" * 60)
        print("[HYBRID] Job-fit request received")

        # Check cache first
        key = cache_key(req.job)
        if key in CACHE:
            print(f"[CACHE] Hit for key: {key[:16]}...")
            return CACHE[key]

        # Load precomputed data
        resume_kw = get_resume_keywords()
        preferences = get_preferences()

        if not resume_kw:
            return {"error": "Resume not loaded. Call /reload first."}

        # Step 1: Extract job keywords (instant)
        job_kw = extract_keywords(req.job)
        print(f"[KEYWORDS] Job keywords: {job_kw}")

        # Step 2: Calculate match score (instant)
        score, matched, gaps = calculate_match_score(resume_kw, job_kw, preferences)

        # Determine fit level
        if score >= 90:
            level = "Strong Fit"
        elif score >= 70:
            level = "Good Fit"
        elif score >= 50:
            level = "Partial Fit"
        else:
            level = "Weak Fit"

        print(f"[SCORE] {score}/100 ({level})")
        print(f"[MATCH] Matched: {matched}")
        print(f"[GAPS] Missing: {gaps}")

        # Step 3: Use LLM only for verdict (short prompt = fast)
        try:
            prompt = VERDICT_PROMPT.format(
                score=score,
                level=level,
                matched=", ".join(matched[:8]) or "None",
                gaps=", ".join(gaps[:5]) or "None"
            )
            print(f"[LLM] Prompt length: {len(prompt)} chars")

            r = requests.post(
                f"{OLLAMA_HOST}/api/generate",
                json={
                    "model": "gemma:2b",
                    "prompt": prompt,
                    "stream": False,
                    "temperature": 0.3,
                    "format": "json",
                    "keep_alive": "30m"
                },
                timeout=60
            )
            r.raise_for_status()
            text = r.json().get("response", "")
            print(f"[LLM] Response: {text[:200]}...")

            # Parse LLM response
            try:
                llm_result = json.loads(text)
            except:
                llm_result = {"summary": f"Match score {score}% based on keyword analysis.", "verdict": level}

            # Combine precomputed + LLM results
            result = {
                "fit_score": score,
                "fit_level": level,
                "aligned_areas": matched,
                "gaps": gaps,
                "summary": llm_result.get("summary", f"Score: {score}%"),
                "verdict": llm_result.get("verdict", level)
            }

        except Exception as e:
            print(f"[LLM-ERROR] {e} - Using precomputed results only")
            # Fallback: return results without LLM verdict
            result = {
                "fit_score": score,
                "fit_level": level,
                "aligned_areas": matched,
                "gaps": gaps,
                "summary": f"Based on keyword matching: {len(matched)} skills matched, {len(gaps)} gaps identified.",
                "verdict": f"{level} - {score}% match"
            }

        print(f"[OUTPUT] {json.dumps(result)}")
        print("=" * 60)

        CACHE[key] = result
        return result

    @app.get("/health")
    def health():
        return {"status": "ok"}
