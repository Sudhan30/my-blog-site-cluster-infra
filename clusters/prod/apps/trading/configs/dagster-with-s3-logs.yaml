# Dagster Instance Config with S3 Compute Logs
# This configuration adds persistent compute log storage using S3 (or MinIO)

scheduler:
  module: dagster.core.scheduler
  class: DagsterDaemonScheduler

run_coordinator:
  module: dagster.core.run_coordinator
  class: QueuedRunCoordinator

run_launcher:
  module: dagster_k8s
  class: K8sRunLauncher
  config:
    instance_config_map: dagster-instance
    job_namespace: trading
    service_account_name: dagster
    job_image: docker.io/sudhan03/algo-trading:portfolio-tracker-7aee726
    image_pull_policy: Always
    image_pull_secrets:
      - name: docker-hub-creds
    load_incluster_config: true
    env_config_maps:
      - trading-config
    env_secrets:
      - trading-secrets

storage:
  postgres:
    postgres_db:
      hostname: timescaledb
      username:
        env: DB_USER
      password:
        env: DB_PASSWORD
      db_name: trading_db
      port: 5432

# âœ… ADD THIS: S3-compatible compute log storage
compute_logs:
  module: dagster_aws.s3.compute_log_manager
  class: S3ComputeLogManager
  config:
    bucket: "dagster-compute-logs"
    prefix: "dagster-logs/"
    endpoint_url:
      env: S3_ENDPOINT_URL  # For MinIO: http://minio:9000
    use_ssl: false
    region_name: "us-east-1"
    # Credentials from environment (in trading-secrets)
    # AWS_ACCESS_KEY_ID
    # AWS_SECRET_ACCESS_KEY
